{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6acbe06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-18 16:20:23.637846: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-18 16:20:23.637876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[16:20:30] /opt/dgl/src/runtime/tensordispatch.cc:43: TensorDispatcher: dlopen failed: /home/mparadkar/miniconda3/lib/python3.9/site-packages/dgl/tensoradapter/pytorch/libtensoradapter_pytorch_1.12.0.so: cannot open shared object file: No such file or directory\n",
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_gnn as tfgnn\n",
    "import torch as th\n",
    "from torch import nn as nn\n",
    "import torch_geometric as pyg\n",
    "import dgl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5622e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {\n",
    "    \"airframe\": th.eye(4, 3),\n",
    "    \"powerplant\": th.eye(3, 2),\n",
    "}\n",
    "edge_index_dict = {\n",
    "    (\"airplane\", \"powered by\", \"powerplant\"): th.tensor(\n",
    "        [[0, 1, 2, 3],\n",
    "         [0, 1, 2, 1]]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7280068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "data = HeteroData()\n",
    "data['airframe'].x = th.eye(4, 3)\n",
    "data['powerplant'].x = th.eye(3, 2)\n",
    "data['airframe', 'powered by', 'powerplant'].edge_index = th.tensor(\n",
    "        [[0, 1, 2, 3],\n",
    "         [0, 1, 2, 1]]\n",
    "    )\n",
    "data['airframe', 'developed from', 'airframe'].edge_index = th.tensor(\n",
    "        [[1, 3],\n",
    "         [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54fb2d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[1, 3, 0, 1, 2, 3],\n",
       "        [0, 1, 0, 1, 2, 3]])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "T.AddSelfLoops()(data)['airframe', 'developed from', 'airframe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe90252c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'edge_index': tensor([[0, 1, 2, 3],\n",
       "        [0, 1, 2, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.AddSelfLoops()(data)['airframe', 'powered by', 'powerplant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57975a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.edge_stores[1].is_bipartite()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eac43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "channels_dict = {node_type: data[node_type].num_features for node_type in data.node_types}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f23bfea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['airframe'].num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d401c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgtc_pyg = pyg.nn.HGTConv(in_channels=channels_dict, out_channels=2, metadata=data.metadata(), heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df2a2d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleDict(\n",
       "  (airframe): Linear(3, 2, bias=True)\n",
       "  (powerplant): Linear(2, 2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgtc_pyg.k_lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0b65ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgtc_pyg.p_rel['airframe__powered by__powerplant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f0a740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airframe': tensor([[ 0.3397, -0.5333],\n",
       "         [ 0.2330, -0.6602],\n",
       "         [ 0.3285, -0.5557],\n",
       "         [ 0.2179, -0.6497]], grad_fn=<AddmmBackward0>),\n",
       " 'powerplant': tensor([[0.5096, 0.3893],\n",
       "         [0.0470, 0.6210],\n",
       "         [0.1575, 0.3758]], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hgtc_pyg(data.x_dict, data.edge_index_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c96f73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Dict, List, Optional, Union, Any\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn import init, Parameter\n",
    "from torch_sparse import SparseTensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.dense import Linear\n",
    "from torch_geometric.nn.inits import glorot, ones, reset\n",
    "from torch_geometric.typing import EdgeType, Metadata, NodeType\n",
    "from torch_geometric.utils import softmax\n",
    "\n",
    "def eye(value: Any):\n",
    "    if isinstance(value, Tensor):\n",
    "        init.eye_(value)\n",
    "    else:\n",
    "        for v in value.parameters() if hasattr(value, 'parameters') else []:\n",
    "            eye(v)\n",
    "        for v in value.buffers() if hasattr(value, 'buffers') else []:\n",
    "            eye(v)\n",
    "            \n",
    "def group(xs: List[Tensor], aggr: Optional[str]) -> Optional[Tensor]:\n",
    "    if len(xs) == 0:\n",
    "        return None\n",
    "    elif aggr is None:\n",
    "        return torch.stack(xs, dim=1)\n",
    "    elif len(xs) == 1:\n",
    "        return xs[0]\n",
    "    else:\n",
    "        out = torch.stack(xs, dim=0)\n",
    "        out = getattr(torch, aggr)(out, dim=0)\n",
    "        out = out[0] if isinstance(out, tuple) else out\n",
    "        return out\n",
    "\n",
    "\n",
    "class HackedGTConv(MessagePassing):\n",
    "    r\"\"\"The Heterogeneous Graph Transformer (HGT) operator from the\n",
    "    `\"Heterogeneous Graph Transformer\" <https://arxiv.org/abs/2003.01332>`_\n",
    "    paper.\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using HGT, see `examples/hetero/hgt_dblp.py\n",
    "        <https://github.com/pyg-team/pytorch_geometric/blob/master/examples/\n",
    "        hetero/hgt_dblp.py>`_.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int or Dict[str, int]): Size of each input sample of every\n",
    "            node type, or :obj:`-1` to derive the size from the first input(s)\n",
    "            to the forward method.\n",
    "        out_channels (int): Size of each output sample.\n",
    "        metadata (Tuple[List[str], List[Tuple[str, str, str]]]): The metadata\n",
    "            of the heterogeneous graph, *i.e.* its node and edge types given\n",
    "            by a list of strings and a list of string triplets, respectively.\n",
    "            See :meth:`torch_geometric.data.HeteroData.metadata` for more\n",
    "            information.\n",
    "        heads (int, optional): Number of multi-head-attentions.\n",
    "            (default: :obj:`1`)\n",
    "        group (string, optional): The aggregation scheme to use for grouping\n",
    "            node embeddings generated by different relations.\n",
    "            (:obj:`\"sum\"`, :obj:`\"mean\"`, :obj:`\"min\"`, :obj:`\"max\"`).\n",
    "            (default: :obj:`\"sum\"`)\n",
    "        **kwargs (optional): Additional arguments of\n",
    "            :class:`torch_geometric.nn.conv.MessagePassing`.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: Union[int, Dict[str, int]],\n",
    "        out_channels: int,\n",
    "        metadata: Metadata,\n",
    "        heads: int = 1,\n",
    "        group: str = \"sum\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(aggr='add', node_dim=0, **kwargs)\n",
    "\n",
    "        if not isinstance(in_channels, dict):\n",
    "            in_channels = {node_type: in_channels for node_type in metadata[0]}\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.group = group\n",
    "\n",
    "        self.k_lin = torch.nn.ModuleDict()\n",
    "        self.q_lin = torch.nn.ModuleDict()\n",
    "        self.v_lin = torch.nn.ModuleDict()\n",
    "        self.a_lin = torch.nn.ModuleDict()\n",
    "        self.skip = torch.nn.ParameterDict()\n",
    "        for node_type, in_channels in self.in_channels.items():\n",
    "            self.k_lin[node_type] = Linear(in_channels, out_channels, bias=False)\n",
    "            self.q_lin[node_type] = Linear(in_channels, out_channels, bias=False)\n",
    "            self.v_lin[node_type] = Linear(in_channels, out_channels, bias=False)\n",
    "            self.a_lin[node_type] = Linear(out_channels, out_channels, bias=False)\n",
    "            self.skip[node_type] = Parameter(torch.Tensor(1))\n",
    "\n",
    "        self.a_rel = torch.nn.ParameterDict()\n",
    "        self.m_rel = torch.nn.ParameterDict()\n",
    "        self.p_rel = torch.nn.ParameterDict()\n",
    "        dim = out_channels // heads\n",
    "        for edge_type in metadata[1]:\n",
    "            edge_type = '__'.join(edge_type)\n",
    "            self.a_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))\n",
    "            self.m_rel[edge_type] = Parameter(torch.Tensor(heads, dim, dim))\n",
    "            self.p_rel[edge_type] = Parameter(torch.Tensor(heads))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for val in self.k_lin.values():\n",
    "            init.eye_(val.weight)\n",
    "        for val in self.q_lin.values():\n",
    "            init.eye_(val.weight)\n",
    "        for val in self.v_lin.values():\n",
    "            init.eye_(val.weight)\n",
    "        for val in self.a_lin.values():\n",
    "            init.eye_(val.weight)\n",
    "        ones(self.skip)\n",
    "        ones(self.p_rel)\n",
    "        ones(self.a_rel)\n",
    "        ones(self.m_rel)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x_dict: Dict[NodeType, Tensor],\n",
    "        edge_index_dict: Union[Dict[EdgeType, Tensor],\n",
    "                               Dict[EdgeType, SparseTensor]]  # Support both.\n",
    "    ) -> Dict[NodeType, Optional[Tensor]]:\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            x_dict (Dict[str, Tensor]): A dictionary holding input node\n",
    "                features  for each individual node type.\n",
    "            edge_index_dict (Dict[str, Union[Tensor, SparseTensor]]): A\n",
    "                dictionary holding graph connectivity information for each\n",
    "                individual edge type, either as a :obj:`torch.LongTensor` of\n",
    "                shape :obj:`[2, num_edges]` or a\n",
    "                :obj:`torch_sparse.SparseTensor`.\n",
    "\n",
    "        :rtype: :obj:`Dict[str, Optional[Tensor]]` - The output node embeddings\n",
    "            for each node type.\n",
    "            In case a node type does not receive any message, its output will\n",
    "            be set to :obj:`None`.\n",
    "        \"\"\"\n",
    "\n",
    "        H, D = self.heads, self.out_channels // self.heads\n",
    "\n",
    "        k_dict, q_dict, v_dict, out_dict = {}, {}, {}, {}\n",
    "\n",
    "        # Iterate over node-types:\n",
    "        for node_type, x in x_dict.items():\n",
    "            k_dict[node_type] = self.k_lin[node_type](x).view(-1, H, D)\n",
    "            q_dict[node_type] = self.q_lin[node_type](x).view(-1, H, D)\n",
    "            v_dict[node_type] = self.v_lin[node_type](x).view(-1, H, D)\n",
    "            out_dict[node_type] = []\n",
    "\n",
    "        # Iterate over edge-types:\n",
    "        for edge_type, edge_index in edge_index_dict.items():\n",
    "            src_type, _, dst_type = edge_type\n",
    "            edge_type = '__'.join(edge_type)\n",
    "\n",
    "            a_rel = self.a_rel[edge_type]\n",
    "            k = (k_dict[src_type].transpose(0, 1) @ a_rel).transpose(1, 0)\n",
    "\n",
    "            m_rel = self.m_rel[edge_type]\n",
    "            v = (v_dict[src_type].transpose(0, 1) @ m_rel).transpose(1, 0)\n",
    "\n",
    "            # propagate_type: (k: Tensor, q: Tensor, v: Tensor, rel: Tensor)\n",
    "            out = self.propagate(edge_index, k=k, q=q_dict[dst_type], v=v,\n",
    "                                 rel=self.p_rel[edge_type], size=None)\n",
    "            out_dict[dst_type].append(out)\n",
    "\n",
    "        # Iterate over node-types:\n",
    "        for node_type, outs in out_dict.items():\n",
    "            out = group(outs, self.group)\n",
    "\n",
    "            if out is None:\n",
    "                out_dict[node_type] = None\n",
    "                continue\n",
    "\n",
    "            out = self.a_lin[node_type](F.gelu(out))\n",
    "            if out.size(-1) == x_dict[node_type].size(-1):\n",
    "                alpha = self.skip[node_type].sigmoid()\n",
    "                out = alpha * out + (1 - alpha) * x_dict[node_type]\n",
    "            out_dict[node_type] = out\n",
    "\n",
    "        return out_dict\n",
    "\n",
    "\n",
    "    def message(self, k_j: Tensor, q_i: Tensor, v_j: Tensor, rel: Tensor,\n",
    "                index: Tensor, ptr: Optional[Tensor],\n",
    "                size_i: Optional[int]) -> Tensor:\n",
    "\n",
    "        alpha = (q_i * k_j).sum(dim=-1) * rel\n",
    "        alpha = alpha / math.sqrt(q_i.size(-1))\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        out = v_j * alpha.view(-1, self.heads, 1)\n",
    "        return out.view(-1, self.out_channels)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(-1, {self.out_channels}, '\n",
    "                f'heads={self.heads})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cec76301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'airframe': tensor([[0.6764, 0.2102],\n",
       "         [0.0000, 0.6764],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]], grad_fn=<MmBackward0>),\n",
       " 'powerplant': tensor([[0.8840, 0.0000],\n",
       "         [0.0000, 0.6792],\n",
       "         [0.0000, 0.0000]], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hacked_pyg = HackedGTConv(in_channels=channels_dict, out_channels=2, metadata=data.metadata(), heads=2)\n",
    "hacked_pyg(data.x_dict, data.edge_index_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
